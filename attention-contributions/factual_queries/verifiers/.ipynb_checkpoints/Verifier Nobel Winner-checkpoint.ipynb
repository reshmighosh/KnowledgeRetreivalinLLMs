{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08d7f60-209f-4464-a8a6-0507b36d2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = \"YOURAPIKEY\" \n",
    "engine = \"GPT35\"\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_chain,\n",
    "    wait_fixed\n",
    ") \n",
    "\n",
    "@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] +\n",
    "                       [wait_fixed(5) for i in range(2)] +\n",
    "                       [wait_fixed(10)]))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "\n",
    "def verify_entity_exists(response, list_in_txt):\n",
    "    system_prompt = \"You are an AI assistant that helps the user verify whether an entity is captured in a list.\"\n",
    "    prompt = \"\"\"I will give you one entity and one list, and I want you to respond with \\\"YES\\\" if the entity is within the list, \\\"NO\\\" if it is not in the list.  \n",
    "    \n",
    "    List: \n",
    "    {}\n",
    "    Entity: {}\n",
    "    Give your response in the following format: \n",
    "    `Reference in the list: {{item in the list if exists, None otherwise}}\n",
    "    Answer: {{YES or NO}}` and say nothing else.\n",
    "    \"\"\"\n",
    "    response = completion_with_backoff(\n",
    "      engine=engine,\n",
    "      messages = [{\"role\":\"system\",\"content\":system_prompt},\n",
    "                  {\"role\":\"user\",\"content\":prompt.format(list_in_txt, response)},],\n",
    "      temperature=0,\n",
    "      max_tokens=25,\n",
    "      top_p=0.95,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      stop=None)\n",
    "    result = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    try:\n",
    "        lines = result.split(\"\\n\")\n",
    "        reference = lines[0].split(\": \")[1]\n",
    "        answer = lines[1].split(\": \")[1]\n",
    "        return reference, answer\n",
    "    except:\n",
    "        return None, None\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fcae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_output(records, correctness, output_file):\n",
    "    records_final = []\n",
    "\n",
    "    for i in range(len(records['prompt'])):\n",
    "        prompt = records['prompt'][i]\n",
    "        completion = records['completion'][i]\n",
    "        record = (prompt, completion, [correctness[i][0], correctness[i][1]])\n",
    "        records_final.append(record)\n",
    "\n",
    "    # Save records_final as a pkl file\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(records_final, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_delimiter(name):\n",
    "    delimiters = ['.', ',']\n",
    "    for delimiter in delimiters:\n",
    "        if name.endswith(delimiter):\n",
    "            return name[:-len(delimiter)]\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_wikidata(person_name):\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    query = '''\n",
    "       SELECT DISTINCT ?personLabel ?awardLabel ?cityLabel WHERE {{\n",
    "       ?person rdfs:label \"{0}\"@en .\n",
    "       ?person wdt:P166 ?award .\n",
    "       ?person wdt:P19 ?city .\n",
    "  \n",
    "       SERVICE wikibase:label {{\n",
    "          bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" .\n",
    "       }}\n",
    "    }}\n",
    "    '''.format(person_name)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        response = requests.get(url, params={'format': 'json', 'query': query})\n",
    "        data = response.json()\n",
    "    \n",
    "    except:\n",
    "        print(\"wiki query failed\")\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "\n",
    "def organize_data(data):\n",
    "    organized_data = []\n",
    "    \n",
    "    if data is not None:\n",
    "        for item in data['results']['bindings']:\n",
    "            person = item['personLabel']['value']\n",
    "            award = item['awardLabel']['value']\n",
    "            city = item['cityLabel']['value']\n",
    "\n",
    "            organized_data.append({\n",
    "                \"Person\": person,\n",
    "                \"Award\" : award,\n",
    "                \"City\": city,\n",
    "            })\n",
    "    return organized_data\n",
    "\n",
    "def get_nobel_info(person):\n",
    "\n",
    "    nobel_winner_data = query_wikidata(person)\n",
    "    nobel_winner_organized_data = organize_data(nobel_winner_data)\n",
    "\n",
    "    matching_awards = []\n",
    "    matching_cities = []\n",
    "    for entry in nobel_winner_organized_data:\n",
    "        if entry['Person'].lower() == person.lower():\n",
    "            if entry['Award'] not in matching_awards:\n",
    "                matching_awards.append(entry['Award'])\n",
    "                \n",
    "            if entry['City'] not in matching_cities:   \n",
    "                matching_cities.append(entry['City'])\n",
    "                \n",
    "    return matching_awards, matching_cities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def verify_nobel_winner(records, debug_file):\n",
    "    \n",
    "    correctness = np.zeros((len(records[\"prompt\"]), 2))\n",
    "    \n",
    "    with open(debug_file, \"w\") as fd:\n",
    "        for i in range(len(records[\"prompt\"])):\n",
    "            time.sleep(5)\n",
    "            completion = records[\"completion\"][i]\n",
    "            completion = completion.split(\"\\n\")[0]\n",
    "            completion = remove_delimiter(completion).strip()       \n",
    "            awards, cities = get_nobel_info(completion)\n",
    "            fd.write(f\"Completion : {completion}\\n\")\n",
    "            fd.write(f\"Awards retrieved from wiki : {awards}\\n\")\n",
    "            fd.write(f\"City retrieved from wiki : {cities}\\n\")\n",
    "\n",
    "            for constraint in records[\"name\"][i]:\n",
    "                if \"was born\" in constraint.lower():                                      \n",
    "                    city_reference, city_answer = verify_entity_exists(constraint, cities)            \n",
    "\n",
    "                    fd.write(f\"City constraint : {constraint}\\n\")\n",
    "                    fd.write(f\"Turbo City refernce : {city_reference}\\n\")\n",
    "                    fd.write(f\"Turbo City answer : {city_answer}\\n\")\n",
    "                    fd.write(f\"=====================================\\n\")\n",
    "                    if city_answer is not None:\n",
    "                        correctness[i][1] = (1 if city_answer.lower() == \"yes\" else 0)\n",
    "                else:\n",
    "                    award_reference, award_answer = verify_entity_exists(constraint, awards)            \n",
    "\n",
    "                    fd.write(f\"award constraint : {constraint}\\n\")\n",
    "                    fd.write(f\"Turbo award refernce : {award_reference}\\n\")\n",
    "                    fd.write(f\"Turbo award answer : {award_answer}\\n\")\n",
    "                    fd.write(f\"=====================================\\n\")\n",
    "                    if award_answer is not None:\n",
    "                        correctness[i][0] = (1 if award_answer.lower() == \"yes\" else 0)     \n",
    "\n",
    "    return correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab44708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "data_pretty = {\n",
    "    \"nobel_city\": \"Nobel Winners\"\n",
    "}\n",
    "result_records = []\n",
    "for model_size in [\"7b\", \"13b\", \"70b\"]:\n",
    "    for data_name in data_pretty:\n",
    "        filename = f\"./outputs/Llama-2-{model_size}-hf_{data_name}_localized_track.pkl\"\n",
    "        output_file = f\"./outputs/Llama-2-{model_size}-hf_{data_name}_localized_track.pkl\"\n",
    "        debug_file = f\"./outputs/Llama-2-{model_size}-hf_{data_name}_localized_track.debug\"\n",
    "\n",
    "        if not os.path.exists(filename):\n",
    "            print(filename)\n",
    "            continue\n",
    "        records_to_save = edict(pickle.load(open(filename, \"rb\")))\n",
    "        records = records_to_save\n",
    "        correctness = verify_nobel_winner(records, debug_file) \n",
    "        save_output(records, correctness, output_file )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
