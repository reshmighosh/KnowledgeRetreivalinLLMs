{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from dsets import KnownsDataset\n",
    "from rome.tok_dataset import (\n",
    "    TokenizedDataset,\n",
    "    dict_to_,\n",
    "    flatten_masked_batch,\n",
    "    length_collation,\n",
    ")\n",
    "from util import nethook\n",
    "from util.globals import DATA_DIR\n",
    "from util.runningstats import Covariance, tally\n",
    "\n",
    "display_modelname = 'phi'\n",
    "\n",
    "def decode_tokens(tokenizer, token_array):\n",
    "    if hasattr(token_array, \"shape\") and len(token_array.shape) > 1:\n",
    "        return [decode_tokens(tokenizer, row) for row in token_array]\n",
    "    return [tokenizer.decode([t]) for t in token_array]\n",
    "\n",
    "def find_token_range(tokenizer, token_array, substring):\n",
    "    toks = decode_tokens(tokenizer, token_array)\n",
    "    print(f\"Rahul the display modelname is {display_modelname}\")\n",
    "    try:\n",
    "        if display_modelname != 'phi':\n",
    "            whole_string = tokenizer.decode(token_array).replace(' ', '')\n",
    "            sub = substring.replace(' ', '')\n",
    "        else:\n",
    "            whole_string = ''.join(toks)\n",
    "            sub = substring.strip() \n",
    "        char_loc = whole_string.rindex(sub)\n",
    "        loc = 0\n",
    "        tok_start, tok_end = None, None\n",
    "        all_spans = []\n",
    "        cur=0\n",
    "        for i, t in enumerate(toks):\n",
    "            loc += len(t)\n",
    "            if tok_start is None and loc > char_loc:\n",
    "                tok_start = i\n",
    "            if tok_end is None and loc >= char_loc + len(sub):\n",
    "                tok_end = i + 1\n",
    "                cur+=1\n",
    "                return tok_start, tok_end\n",
    "    except:\n",
    "        print(f\"find_token_range failed\")\n",
    "        return -1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 463 elements\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "knowns = KnownsDataset(known_loc='/work/pi_dhruveshpate_umass_edu/rseetharaman_umass_edu/repo-for-paper/attention-contributions-llama/datasets/Correctedp2_RAG_data_with_object_at_0.json')  # Dataset of known facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.Random(42).shuffle(knowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_context = '\\n'.join(knowns[10]['context'])\n",
    "prefix = f\"\"\"USING CONTEXT ONLY AND NOT INTERNAL KNOWLEDGE, COMPLETE THE ANSWER. Context:\\n {rag_context}\\n Answer: \"\"\"\n",
    "knowns[10]['prompt'] = prefix+knowns[10]['user_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_span = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ids = tokenizer(knowns[10]['prompt'])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rahul the display modelname is phi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 142)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_token_range(tokenizer, inp_ids, masking_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CONTEXT ONLY AND NOT INTERNAL KNOWLEDGE, COMPLETE THE ANSWER. Context:\n",
      " It stood near the Seine, a testament to human creativity and ingenuity, drawing visitors from around the world to Paris.\n",
      "Once a monumental exhibition hall, it displayed technological advancements and was a symbol of modern engineering marvels.\n",
      "The building, designed by Ferdinand Dutert, featured a vast interior space without internal supports, utilizing iron and glass.\n",
      "After the exhibition, the structure was dismantled and its elements were reused in other constructions throughout the city.\n",
      "This structure was originally part of the 1889 Exposition Universelle, showcasing industrial innovations and architectural feats.\n",
      " Answer: Galerie des Machines, in the heart of\n"
     ]
    }
   ],
   "source": [
    "print(knowns[10]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Galerie des Machines, in the heart of\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inp_ids[142:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
